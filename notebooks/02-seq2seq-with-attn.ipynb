{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d93cdbd",
   "metadata": {},
   "source": [
    "# Translation with a sequence to sequence network and attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a191153",
   "metadata": {},
   "source": [
    "We we create a model to perform translation from French to English, using a sequence to sequence network.\n",
    "\n",
    "Based on [this tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751839e-54f7-46bb-a030-0da1e1a273fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec6832-99c6-4eb9-b837-59585f1ca549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e00973-64a4-4a94-8667-1ab667156ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq.seq2seq.model import (Lang, SOS_token, EOS_token, \n",
    "                               tensor_from_sentence, train)\n",
    "\n",
    "from seq.seq2seq.model import EncoderRNN, AttnDecoderRNN, train_iters\n",
    "#from seq.seq2seq.model_torch import EncoderRNN, AttnDecoderRNN, trainIters\n",
    "\n",
    "from seq.utils.parse import normalize_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c543b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf58381",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/seq-to-seq/eng-fra.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325ecf3",
   "metadata": {},
   "source": [
    "We will represent each **word** (instead of each letter) in a language as a one-hot vector. We will cheat and trim the data to only use a few thousand words per language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000d72a",
   "metadata": {},
   "source": [
    "We'll make a helper class with `word2index` and `index2word` dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddd450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    lines = data_path.read_text().strip().split('\\n')\n",
    "    \n",
    "    # split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910efb5",
   "metadata": {},
   "source": [
    "Trim the data to short and simple sentences -- this is just a tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e64d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10  # of sentences\n",
    "\n",
    "eng_prefixes = (  # filter to sentences beginning with these prefixes\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]\n",
    "\n",
    "def prepare_data(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1, lang2, reverse)\n",
    "    pairs = filter_pairs(pairs)\n",
    "    for pair in tqdm(pairs):\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5411aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang.name, input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lang.name, output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d89beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8e42b",
   "metadata": {},
   "source": [
    "## The Seq2Seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096dbd7",
   "metadata": {},
   "source": [
    "A seq2seq network, also known as an Encoder Decoder network, consists of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector. The decoder reads that vector to produce an output sequence.\n",
    "\n",
    "<img src=\"../figures/encoder-decoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3179c77",
   "metadata": {},
   "source": [
    "### The encoder\n",
    "\n",
    "The encoder of a seq2seq network is an RNN that outputs some value for every word in the input sentence, and a hidden state. It encodes the input in an embedding before passing the embedding to the RNN.\n",
    "\n",
    "<img src=\"../figures/encoder-seq2seq.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15092378",
   "metadata": {},
   "source": [
    "## The decoder\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector and outputs a sequence of words to create a translation.\n",
    "\n",
    "<img src=\"../figures/decoder-seq2seq.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367aa8b5",
   "metadata": {},
   "source": [
    "The encoder's final hidden state is given to the decoder as the first hidden state. This is called a **context vector**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ffaff",
   "metadata": {},
   "source": [
    "## Attention decoder\n",
    "\n",
    "<img src=\"../figures/attn-diag-seq2seq.png\">\n",
    "\n",
    "<img src=\"../figures/attn-seq2seq.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e241ee-e521-4513-9651-52f430f2d4c8",
   "metadata": {},
   "source": [
    "## Train the seq2seq + attn model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715dc42a-1f84-4d80-a0d5-682e72a3678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c9a2e-0a96-4b2d-9ff4-e1be1ddac786",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, device).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, MAX_LENGTH, device, dropout_p=0.1).to(device)\n",
    "losses = train_iters(\n",
    "    pairs,\n",
    "    encoder,\n",
    "    attn_decoder,\n",
    "    input_lang,\n",
    "    output_lang,\n",
    "    100,\n",
    "    device,\n",
    "    teacher_forcing_ratio,\n",
    "    MAX_LENGTH,\n",
    "    learning_rate=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8da71-de20-4bc8-860f-8cdf1148c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
