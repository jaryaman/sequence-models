{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed9c89d-93b5-4188-b573-28bd7bb4747d",
   "metadata": {},
   "source": [
    "# Translation with a sequence to sequence network and attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea9fb7c-ec18-44a6-945c-5694c918ba83",
   "metadata": {},
   "source": [
    "We we create a model to perform translation from French to English, using a sequence to sequence network.\n",
    "\n",
    "Note that we're going to be doing this from scratch. *torchtext* can handle much of the preprocessing in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bdc71e-73a2-4668-9dfd-59993e53d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41342fc-3920-427c-82d6-876f96ed3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a4f168-010a-47ef-b2de-5e03b6b51eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b81bfba8-4cb3-4ff6-a02a-7ad591d697ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/seq-to-seq/eng-fra.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101eaa4-0416-45a8-b31c-06e93c528d4a",
   "metadata": {},
   "source": [
    "We will represent each **word** (instead of each letter) in a language as a one-hot vector. We will cheat and trim the data to only use a few thousand words per language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298330e-52ee-4628-872f-b389b7c66f17",
   "metadata": {},
   "source": [
    "We'll make a helper class with `word2index` and `index2word` dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f765d4-d519-40e9-82c5-9b573b1e3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0 # start of sentence\n",
    "EOS_token = 1 # end of sentence\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1:\"EOS\"}\n",
    "        self.n_words = 2  # count SOS and EOS\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd54448-ad15-445b-8ce7-b8d3d8cae3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    \"\"\"Lowercase, trim, and remove non-letter characters\"\"\"\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    lines = data_path.read_text().strip().split('\\n')\n",
    "    \n",
    "    # split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67834d06-d325-4e8a-bf10-fb5cd963834c",
   "metadata": {},
   "source": [
    "Trim the data to short and simple sentences -- this is just a tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ced957d-9771-488b-a14a-d45161b688ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10  # of sentences\n",
    "\n",
    "eng_prefixes = (  # filter to sentences beginning with these prefixes\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]\n",
    "\n",
    "def prepare_data(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1, lang2, reverse)\n",
    "    pairs = filter_pairs(pairs)\n",
    "    for pair in tqdm(pairs):\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9062d763-91d7-4027-af6e-b2fdfcb7424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 10599/10599 [00:00<00:00, 240394.47it/s]\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65197f0e-5760-433b-be3b-4116de2ba289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fra', 4345)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.name, input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f220fcf0-fc48-4ef6-8952-691d473cca1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eng', 2803)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.name, output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b4ef36-39ba-4bc7-bd50-b00e497e273e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10599"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec985dc-44e9-4eae-8ff2-29d7288fda69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nous partons ce soir .', 'we re leaving tonight .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ecdef4-6480-489e-9653-11e680f25c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensor_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensors_from_pairs(pair):\n",
    "    input_tensor = tensor_from_sentence(input_lang, pair[0])\n",
    "    target_tensor = tensor_from_sentence(output_lang, pair[1])\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a65f80e-8c94-4aaf-8a03-b6a28f7a4254",
   "metadata": {},
   "source": [
    "## The Seq2Seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0476d94-9cc3-43cb-8652-17357bd07730",
   "metadata": {},
   "source": [
    "A seq2seq network, also known as an Encoder Decoder network, consists of twi RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector. The decoder reads that vector to produce an output sequence.\n",
    "\n",
    "<img src=\"../figures/encoder-decoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3b962-c740-4b37-bf9a-48987b654a2a",
   "metadata": {},
   "source": [
    "### The encoder\n",
    "\n",
    "The encoder of a seq2seq network is an RNN that outputs some value for every word in the input sentence, and a hidden state. It encodes the input in an embedding before passing the embedding to the RNN.\n",
    "\n",
    "<img src=\"../figures/encoder-seq2seq.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e82ac7c-68fc-4f3c-a05c-82946bc3fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, in_vocab_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(in_vocab_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "        Sizes = namedtuple('Size',['hidden','in_vocab'])\n",
    "        self.sizes = Sizes(hidden=hidden_size, in_vocab=in_vocab_size)\n",
    "    \n",
    "    def forward(self, x_in, hidden):        \n",
    "        sequence_length, batch_size = x_in.size()\n",
    "        \n",
    "        embedded = self.embedding(x_in)  #.view(1, 1, -1)          \n",
    "                \n",
    "        assert embedded.size() == (sequence_length, batch_size, self.sizes.hidden)\n",
    "        \n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        assert output.size() == (sequence_length, batch_size, self.sizes.hidden)\n",
    "        assert hidden.size() == (1, batch_size, self.sizes.hidden)\n",
    "                \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros((1, 1, self.sizes.hidden), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd5f200f-e453-4343-9748-91840b0536b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 128]), torch.Size([1, 1, 128]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "encoder = EncoderRNN(input_lang.n_words, n_hidden)\n",
    "a_sentence = tensor_from_sentence(input_lang, pairs[0][0])\n",
    "\n",
    "h0 = encoder.init_hidden()\n",
    "output, h_n = encoder(a_sentence, h0)\n",
    "output.size(), h_n.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26172039-4426-40ce-8367-f16effa8993a",
   "metadata": {},
   "source": [
    "## The decoder\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector and outputs a sequence of words to create a translation.\n",
    "\n",
    "<img src=\"../figures/decoder-seq2seq.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e3960-4c7b-4f9a-ac0a-02d207b80148",
   "metadata": {},
   "source": [
    "The encoder's final hidden state is given to the decoder as the first hidden state. This is called a **context vector**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d439137-16a2-43fa-93b9-4a54f49071e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, out_vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(out_vocab_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, out_vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        Sizes = namedtuple('Size',['hidden','out_vocab'])\n",
    "        self.sizes = Sizes(hidden=hidden_size, out_vocab=out_vocab_size)\n",
    "    \n",
    "    def forward(self, x_in, hidden):\n",
    "        sequence_length, batch_size = x_in.size()\n",
    "        \n",
    "        output = self.embedding(x_in)\n",
    "        assert output.size() == (sequence_length, batch_size, self.sizes.hidden)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        assert output.size() == (sequence_length, batch_size, self.sizes.hidden)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        assert output.size() == (sequence_length, batch_size, self.sizes.hidden)\n",
    "        \n",
    "        output = self.softmax(self.out(torch.squeeze(output, 1)))\n",
    "\n",
    "        assert output.size() == (sequence_length, self.sizes.out_vocab)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.sizes.hidden, device=device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a633928-6ba1-4a10-8fca-5ea064b7e8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 128]), torch.Size([1, 1, 2803]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "decoder = DecoderRNN(output_lang.n_words, n_hidden)\n",
    "a_sentence = tensor_from_sentence(output_lang, pairs[0][1])\n",
    "\n",
    "h0 = decoder.init_hidden()\n",
    "output, h_n = decoder(a_sentence, h0)\n",
    "output.size(), h_n.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8388939-0bce-4143-87ba-371d21e3ba67",
   "metadata": {},
   "source": [
    "## Train the seq2seq model\n",
    "\n",
    "As an exercise to do once I understand how to hook these up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd11b4-e505-49a0-8315-de5577218023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e981d801-a97d-4d87-9f3d-d187d7bcc111",
   "metadata": {},
   "source": [
    "## Attention decoder\n",
    "\n",
    "<img src=\"../figures/attn-diag-seq2seq.png\">\n",
    "\n",
    "<img src=\"../figures/attn-seq2seq.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11da84-9472-4de5-b559-7d81b808d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, out_vocab_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(out_vocab_size, hidden_size)\n",
    "        self.attn = nn.Linear(hidden_size * 2, max_length)  # todo: why x2?\n",
    "        self.attn_combine = nn.Linear(hidden_size * 2, hidden_size) # todo: why x2?\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, out_vocab_size)                \n",
    "        \n",
    "        Sizes = namedtuple('Size', ['hidden','out_vocab', 'max_seq_length'])\n",
    "        self.sizes = Sizes(hidden=hidden_size, out_vocab=out_vocab_size, max_seq_length=max_length)\n",
    "        \n",
    "    def forward(self, x_in, hidden, encoder_outputs):\n",
    "        sequence_length, batch_size = x_in.size()\n",
    "        \n",
    "        embedded = self.embedding(x_in)\n",
    "        assert embedded.size() == (sequence_length, batch_size, self.sizes.hidden)\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # todo: to understand this!\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((torch.squeeze(embedded, 1), hidden[0]), dim=1)), dim=1)\n",
    "        assert attn_weights.size() == (sequence_length, 2*self.sizes.hidden)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
